{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "framed-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import statistics as st\n",
    "import datetime\n",
    "import plotly.express\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys\n",
    "consumer_key = \"w0ywEBjife6WBfIVOgMffvlvE\"\n",
    "consumer_secret = \"5T64JvO3J4ftnjyIQolE0J17w0dAXeEDFS9GsyVrzBHgLM5au9\"\n",
    "access_key = \"1361669854269476868-fTDqiXUegqTDQT8tPU5UvMQAxuXGV6\"\n",
    "access_secret = \"zBITqkEyK1A95epa2pn25RrxDs2QnWbs2Ys5am5Pyn0bi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweepy api\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data collection\n",
    "tweets=[]\n",
    "for status in tweepy.Cursor(api.user_timeline,id='DcpNorthDelhi',tweet_mode='extended').items():\n",
    "    tweets.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing tweets in pkl file\n",
    "# open_file = open(\"DcpNorthdelhiTweets.pkl\", \"wb\")\n",
    "# pickle.dump(tweets, open_file)\n",
    "# open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading stored pkl file\n",
    "open_file = open(\"DcpNorthdelhiTweets.pkl\", \"rb\")\n",
    "tweets = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users who have been replied by police\n",
    "replied_users=[]\n",
    "for i in tweets:\n",
    "    if(i.in_reply_to_status_id!=None):\n",
    "        replied_users.append(i.in_reply_to_status_id)  \n",
    "replied_users=list(set(replied_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-ready",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#collecting original tweets for the users in replied_users list\n",
    "original_tweets=[]\n",
    "c=0\n",
    "for i in replied_users:\n",
    "    print(c)\n",
    "    try:\n",
    "        original_tweets.append(api.get_status(i,tweet_mode='extended'))\n",
    "    except:\n",
    "        original_tweets.append(None)\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing tweets in pkl file\n",
    "# ofile = open(\"Replied_tweets.pkl\", \"wb\")\n",
    "# pickle.dump(original_tweets, ofile)\n",
    "# ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading pkl file\n",
    "ofile = open(\"Replied_tweets.pkl\", \"rb\")\n",
    "original_tweets = pickle.load(ofile)\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_id_vs_tweet={}\n",
    "for i in range(len(replied_users)):\n",
    "    if(original_tweets[i]!=None):\n",
    "        original_id_vs_tweet[replied_users[i]]=original_tweets[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "replied_by_police={}\n",
    "for i in tweets:\n",
    "    if(i.in_reply_to_status_id in original_id_vs_tweet):\n",
    "        replied_by_police[i.in_reply_to_status_id]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "email_regex=\"(\\S(\\.|\\w)+[@]+(\\.|\\w)+([.]\\S*))\"\n",
    "mobile_number_regex=\"\\D[0-9]{10}\\D\"\n",
    "aadhar_number_regex=\"\\d{4}\\s\\d{4}\\s\\d{4}\"\n",
    "pincode_regex=\"\\D[1-9]{1}[0-9]{2}[0-9]{3}\\D|\\D[1-9]{1}[0-9]{2}\\D{1}[0-9]{3}\\D\"\n",
    "vehicle_number_regex=\"[A-Z]{2}[0-9]{1,2}(?:[A-Z])?(?:[A-Z]*)?[0-9]{4}\" #taken online\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding different PII\n",
    "tweet_id=[]\n",
    "email_id=[]\n",
    "mobile_number=[]\n",
    "aadhar_number=[]\n",
    "pincode=[]\n",
    "vehicle_number=[]\n",
    "email_id_count=[]\n",
    "mobile_number_count=[]\n",
    "aadhar_number_count=[]\n",
    "pincode_count=[]\n",
    "vehicle_number_count=[]\n",
    "\n",
    "for i in original_id_vs_tweet.keys():\n",
    "    data=original_id_vs_tweet[i].full_text\n",
    "    tweet_id.append(i)\n",
    "    email_id_count.append(len(re.findall(email_regex,data)))\n",
    "    mobile_number_count.append(len(re.findall(mobile_number_regex,data)))\n",
    "    aadhar_number_count.append(len(re.findall(aadhar_number_regex,data)))\n",
    "    pincode_count.append(len(re.findall(pincode_regex,data)))\n",
    "    vehicle_number_count.append(len(re.findall(vehicle_number_regex,data)))\n",
    "    email_id.append(re.findall(email_regex,data))\n",
    "    mobile_number.append(re.findall(mobile_number_regex,data))\n",
    "    aadhar_number.append(re.findall(aadhar_number_regex,data))\n",
    "    pincode.append(re.findall(pincode_regex,data))\n",
    "    vehicle_number.append(re.findall(vehicle_number_regex,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PII table 1\n",
    "data_pii={}\n",
    "data_pii['PII_types']=['emails','mobile_numbers','aadhar_card_numbers','pincode','vehicle_numbers']\n",
    "data_pii['count']=[sum(email_id_count),sum(mobile_number_count),sum(aadhar_number_count),sum(pincode_count),sum(vehicle_number_count)]\n",
    "\n",
    "df_pii_1=pd.DataFrame(data_pii)\n",
    "df_pii_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PII table 2\n",
    "data_pii={}\n",
    "data_pii['Tweet ID']=tweet_id\n",
    "data_pii['no_of_emails']=email_id_count\n",
    "data_pii['no_of_mobile_numbers']=mobile_number_count\n",
    "data_pii['no_of_aadhar_card_no']=aadhar_number_count\n",
    "data_pii['no_of_pincodes']=pincode_count\n",
    "data_pii['no_of_vehicle_numbers']=vehicle_number_count\n",
    "\n",
    "df_pii_1=pd.DataFrame(data_pii)\n",
    "df_pii_1[(df_pii_1['no_of_emails']>0) | (df_pii_1['no_of_mobile_numbers']>0) | (df_pii_1['no_of_aadhar_card_no']>0) | (df_pii_1['no_of_pincodes']>0) | (df_pii_1['no_of_vehicle_numbers']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-delay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tweet_id:\n",
    "    print(original_id_vs_tweet[i].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ques1 part b\n",
    "media_tweets=[]\n",
    "media_tweets_id=[]\n",
    "media_tweets_url=[]\n",
    "for i in original_id_vs_tweet.keys():\n",
    "    data=original_id_vs_tweet[i].entities\n",
    "    if('media' in data):\n",
    "        media_tweets_id.append(i)\n",
    "        media_tweets.append(original_id_vs_tweet[i])\n",
    "        media_tweets_url.append(data['media'][0]['media_url_https'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tweets with media: \",len(media_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links of images\n",
    "for i in media_tweets_url:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ques2\n",
    "id_vs_response_time={}\n",
    "\n",
    "for i in replied_by_police.keys():\n",
    "    id_vs_response_time[i]=replied_by_police[i].created_at-original_id_vs_tweet[i].created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding response time for tweets\n",
    "response_times=id_vs_response_time.values()\n",
    "response_times_seconds=[i.total_seconds() for i in response_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding asked values\n",
    "mean_response_time=datetime.timedelta(seconds=st.mean(response_times_seconds))\n",
    "minimum_response_time=min(response_times)\n",
    "maximum_response_time=max(response_times)\n",
    "standard_deviation_of_response_time=datetime.timedelta(seconds=st.stdev(response_times_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean_response_time:\",mean_response_time)\n",
    "print(\"minimum_response_time:\",minimum_response_time)\n",
    "print(\"maximum_response_time:\",maximum_response_time)\n",
    "print(\"standard_deviation_of_response_time:\",standard_deviation_of_response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis=[]\n",
    "y_axis=[]\n",
    "\n",
    "for i in replied_by_police.keys():\n",
    "    x_axis.append(replied_by_police[i].created_at)\n",
    "    y_axis.append(id_vs_response_time[i].total_seconds())\n",
    "\n",
    "dc={}\n",
    "dc[\"Replied_time_of_police\"]=x_axis\n",
    "dc[\"Response_time\"]=y_axis\n",
    "\n",
    "df_dc=pd.DataFrame(dc)\n",
    "df_dc=df_dc.sort_values(by='Replied_time_of_police')\n",
    "\n",
    "grf=plotly.express.line(df_dc,x='Replied_time_of_police',y='Response_time' ,title=\"Replied tweets of police vs their response time\")\n",
    "grf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ques3\n",
    "#1. appreciation 2. report 3. requests 4. accountability 5. other\n",
    "table_id=[]\n",
    "table_tweet=[]\n",
    "table_classified=[]\n",
    "\n",
    "for i in list(original_id_vs_tweet.values())[70:100]:\n",
    "    print(i.full_text)\n",
    "    j=input()\n",
    "    table_id.append(i.id)\n",
    "    table_tweet.append(i.full_text)\n",
    "    table_classified.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_q3={}\n",
    "dc_q3['Tweet_id']=table_id\n",
    "dc_q3['Tweet']=table_tweet\n",
    "dc_q3['classification']=table_classified\n",
    "\n",
    "dc_q3=pd.DataFrame(dc_q3)\n",
    "dc_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-robin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
